{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfcd1c0",
   "metadata": {},
   "source": [
    "# Task‚ÄØ3: CNN Image Classification on CIFAR‚Äë10 ‚Äì CodTech Internship\n",
    "This notebook builds a **Convolutional Neural Network (CNN)** using TensorFlow/Keras to classify images in the CIFAR‚Äë10 dataset. We include data preprocessing, model definition, training, and performance evaluation on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Load and preprocess CIFAR‚Äë10\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "print('Train shape:', X_train.shape, '| Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c834b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Build CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3232b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Train model (10 epochs)\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddf478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Evaluate on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'üîπ Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc02f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Plot training history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Confusion Matrix & Classification Report\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = y_test.flatten()\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
